name: SecureShield CI/CD Pipeline

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]

# Cancel redundant runs on the same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:

  # ──────────────────────────────────────────────
  # Stage 1: Rust / Wasm unit tests
  # ──────────────────────────────────────────────
  wasm-tests:
    name: "Rust / Wasm Tests"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Rust (stable)
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Cargo registry & build
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            wasm/target
          key: ${{ runner.os }}-cargo-${{ hashFiles('wasm/Cargo.lock') }}
          restore-keys: ${{ runner.os }}-cargo-

      - name: Run Wasm unit tests
        run: |
          cd wasm
          cargo test --verbose

  # ──────────────────────────────────────────────
  # Stage 2: Python / FastAPI integration tests
  # ──────────────────────────────────────────────
  backend-tests:
    name: "Backend Integration Tests"
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: user
          POSTGRES_PASSWORD: password
          POSTGRES_DB: main_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U user -d main_db"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.13
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt

      - name: Run backend tests + coverage (Postgres)
        env:
          # Override conftest.py's SQLite default so CI runs against real Postgres
          DATABASE_URL: postgresql+asyncpg://user:password@localhost:5432/main_db
          RATE_LIMIT_ENABLED: "false"
          ADMIN_API_KEY: test-admin-key-for-ci-not-production
          OFFLINE_TOKEN_SECRET: test-offline-secret-for-jwt-hs256!
          VAULT_TOKEN_SECRET: test-vault-token-secret-for-jwt32!
          SUPER_ADMIN_KEY: test-super-admin-key-ci
          STRIPE_WEBHOOK_SECRET: ${{ secrets.STRIPE_WEBHOOK_SECRET }}
          # VAULT_MASTER_KEY must be base64(32-byte key) — conftest sets a test value
          # via setdefault, but we pin it here so it's visible in the CI log.
          VAULT_MASTER_KEY: dGVzdF92YXVsdF8zMmJ5dGVfa2V5X2Zvcl90ZXN0cyE=
          AWS_ACCESS_KEY_ID: test
          AWS_SECRET_ACCESS_KEY: test
          AWS_DEFAULT_REGION: us-east-1
          S3_BUCKET: test-secureshield-vault
        run: |
          cd backend
          pytest tests/ -v --tb=short \
            --cov=. --cov-config=.coveragerc \
            --cov-report=term-missing:skip-covered \
            --cov-report=xml:coverage.xml \
            --junitxml=test-results.xml

      - name: Upload coverage report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-postgres
          path: backend/coverage.xml
          retention-days: 30

  # ──────────────────────────────────────────────
  # Stage 3: Playwright E2E tests
  # Runs only after wasm + backend both pass
  # ──────────────────────────────────────────────
  frontend-e2e:
    name: "Frontend E2E Tests (Playwright)"
    needs: [ wasm-tests, backend-tests ]
    runs-on: ubuntu-latest

    # Job-level env — inherited by ALL steps and by uvicorn (started via &).
    # Step-level env only survives for that step's shell; background processes
    # that outlive the step need the vars set here so they remain in effect.
    env:
      DATABASE_URL: postgresql+asyncpg://user:password@localhost:5432/main_db
      RATE_LIMIT_ENABLED: "false"
      ADMIN_API_KEY: test-admin-key-for-ci-not-production
      OFFLINE_TOKEN_SECRET: test-offline-secret-for-jwt-hs256!
      VAULT_TOKEN_SECRET: test-vault-token-secret-for-jwt32!
      SUPER_ADMIN_KEY: test-super-admin-key-ci
      VAULT_MASTER_KEY: dGVzdF92YXVsdF8zMmJ5dGVfa2V5X2Zvcl90ZXN0cyE=
      AWS_ACCESS_KEY_ID: test
      AWS_SECRET_ACCESS_KEY: test
      AWS_DEFAULT_REGION: us-east-1
      S3_BUCKET: test-secureshield-vault
      # Force IPv4 so redis.asyncio never tries the IPv6 ::1 path on the runner
      REDIS_URL: redis://127.0.0.1:6379/0

    # Managed services — GitHub Actions starts these containers and waits for
    # them to pass their health checks before running any steps.
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: user
          POSTGRES_PASSWORD: password
          POSTGRES_DB: main_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U user -d main_db"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 5s
          --health-timeout 3s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.13
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Install backend dependencies
        run: cd backend && pip install -r requirements.txt

      # Verify the app can be imported before attempting to start uvicorn.
      # This catches import errors (missing deps, API-breaking package updates)
      # immediately rather than letting them hide behind a 60-second timeout.
      - name: Smoke-test app import
        run: cd backend && python -c "from main import app; print('import OK')"

      # Directly test that DB and Redis are reachable from Python before we start
      # uvicorn. If either connection fails here, we know the problem is network/
      # service config, not the application. Runs in the same env as uvicorn will.
      - name: Pre-flight connectivity test
        run: |
          python - <<'PYEOF'
          import asyncio, os, sys

          async def main():
              errors = []

              # ── PostgreSQL via asyncpg ────────────────────────────────────────
              try:
                  import asyncpg
                  conn = await asyncpg.connect(os.environ["DATABASE_URL"].replace(
                      "postgresql+asyncpg://", "postgresql://"))
                  result = await conn.fetchval("SELECT 1")
                  await conn.close()
                  print(f"[OK] PostgreSQL: SELECT 1 = {result}")
              except Exception as e:
                  errors.append(f"[FAIL] PostgreSQL: {e}")
                  print(errors[-1])

              # ── Redis via redis.asyncio ───────────────────────────────────────
              try:
                  import redis.asyncio as aioredis
                  r = aioredis.Redis.from_url(
                      os.environ.get("REDIS_URL", "redis://127.0.0.1:6379/0"),
                      decode_responses=True)
                  pong = await r.ping()
                  await r.aclose()
                  print(f"[OK] Redis: PING = {pong}")
              except Exception as e:
                  errors.append(f"[FAIL] Redis: {e}")
                  print(errors[-1])

              if errors:
                  sys.exit(1)

          asyncio.run(main())
          PYEOF

      # nohup prevents SIGHUP from killing the child when the step's shell exits.
      # python -m uvicorn guarantees the right interpreter / PATH is used.
      - name: Start backend API
        run: |
          cd backend
          nohup python -m uvicorn main:app --host 0.0.0.0 --port 8001 \
            --log-level info > /tmp/uvicorn.log 2>&1 &
          echo $! > /tmp/uvicorn.pid
          echo "uvicorn started (PID $(cat /tmp/uvicorn.pid))"

      # Always-run diagnostics: shows port, PID state, and log even on success.
      # Runs after the 15-second settle so the lifespan startup has time to finish.
      - name: Diagnose startup (15-second settle)
        if: always()
        run: |
          sleep 15

          # ── console output ────────────────────────────────────────────────────
          echo "=== Listening on :8001 ==="
          ss -tlnp | grep 8001 || netstat -tlnp 2>/dev/null | grep 8001 || echo "nothing on 8001"
          echo "=== uvicorn PID $(cat /tmp/uvicorn.pid 2>/dev/null) alive? ==="
          kill -0 "$(cat /tmp/uvicorn.pid 2>/dev/null)" 2>/dev/null && echo "ALIVE" || echo "DEAD"
          echo "=== uvicorn log ==="
          cat /tmp/uvicorn.log || echo "(no log file)"
          echo "=== /health response ==="
          curl -sv http://localhost:8001/health 2>&1 || echo "(no response)"

          # ── GitHub Step Summary (visible without artifact download) ───────────
          {
            echo "## Uvicorn startup log"
            echo '```'
            cat /tmp/uvicorn.log 2>/dev/null || echo "(no log file)"
            echo '```'
            echo "## /health at t=15s"
            echo '```'
            curl -s http://localhost:8001/health 2>/dev/null || echo "(no response)"
            echo '```'
            echo "## Port :8001 listeners"
            echo '```'
            ss -tlnp | grep 8001 || echo "nothing on 8001"
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      # Explicit loop so every poll prints the full response body; max 30 × 3 s = 90 s.
      # Every attempt is also written to $GITHUB_STEP_SUMMARY so it is visible
      # directly on the run page without needing artifact download or raw-log auth.
      #
      # IMPORTANT: GitHub Actions runs `run:` blocks with `bash -eo pipefail`.
      # `set -e` means that `STATUS=$(curl ...)` will EXIT THE SCRIPT when curl
      # returns non-zero (exit 7 = connection refused). We suppress this with
      # `|| STATUS="000"` so the loop actually runs all 30 iterations.
      - name: Wait for API to be healthy
        run: |
          echo "## /health poll log" >> "$GITHUB_STEP_SUMMARY" || true
          for i in $(seq 1 30); do
            STATUS=$(curl -s -o /dev/null -w "%{http_code}" \
              http://localhost:8001/health 2>/dev/null) || STATUS="000"
            BODY=$(curl -s http://localhost:8001/health 2>&1) || BODY=""
            echo "attempt $i: HTTP $STATUS — $BODY"
            echo "- attempt $i: HTTP $STATUS / body: $BODY" \
              >> "$GITHUB_STEP_SUMMARY" || true
            # Starlette's JSONResponse uses compact separators (no space after :)
            # so the response is  {"status":"healthy",...}  not  {"status": "healthy",...}
            if echo "$BODY" | grep -q '"status":"healthy"'; then
              echo "API is healthy!"; exit 0
            fi
            sleep 3
          done
          {
            echo ""
            echo "**TIMEOUT** — final uvicorn log:"
            echo '```'
            cat /tmp/uvicorn.log 2>/dev/null || echo "(no log)"
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY" || true
          # Emit a GitHub annotation so the last health response is visible
          # in the Checks UI and via the annotations API without auth.
          echo "::error::Health wait timed out. Last STATUS=${STATUS} BODY=${BODY}"
          echo "=== TIMEOUT — final uvicorn log:"; cat /tmp/uvicorn.log; exit 1

      - name: Set up Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"
          cache-dependency-path: frontend/package-lock.json

      - name: Install frontend dependencies
        run: cd frontend && npm ci

      - name: Install Playwright browsers
        run: cd frontend && npx playwright install chromium firefox --with-deps

      - name: Run Playwright E2E tests
        env:
          CI: "true"
          # Playwright's webServer (npm run dev) will inherit this env var
          NEXT_PUBLIC_API_URL: http://localhost:8001
        run: cd frontend && npx playwright test --reporter=github

      - name: Upload uvicorn startup log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: uvicorn-startup-log
          path: /tmp/uvicorn.log
          retention-days: 7
          if-no-files-found: warn

      - name: Upload Playwright report on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: frontend/playwright-report/
          retention-days: 7
